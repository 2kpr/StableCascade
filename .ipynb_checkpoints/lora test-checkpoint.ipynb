{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, CLIPModel, CLIPVisionModelWithProjection\n",
    "from train_c_lora import WurstCore\n",
    "from train_b import WurstCore as WurstCoreB\n",
    "from warp_core.utils import load_or_fail\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459aea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP WARPCORE\n",
    "config_file = 'configs/finetune_c_3b_lora.yml'\n",
    "with open(config_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "    loaded_config['use_fsdp'] = False\n",
    "    loaded_config['batch_size'] = 4\n",
    "\n",
    "warpcore = WurstCore(\n",
    "    config_dict=loaded_config,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# STAGE B\n",
    "config_file_b = 'configs/finetune_b_3b.yml'\n",
    "with open(config_file_b, \"r\", encoding=\"utf-8\") as file:\n",
    "    config_file_b = yaml.safe_load(file)\n",
    "    config_file_b['use_fsdp'] = False\n",
    "    config_file_b['batch_size'] = 4\n",
    "    \n",
    "warpcore_b = WurstCoreB(\n",
    "    config_dict=config_file_b,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b40241ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP MODELS & DATA\n",
    "extras = warpcore.setup_extras_pre()\n",
    "data = warpcore.setup_data(extras)\n",
    "# models = warpcore.setup_models(extras)\n",
    "# models.generator.bfloat16().eval().requires_grad_(False)\n",
    "print(\"CONTROLNET READY\")\n",
    "\n",
    "extras_b = warpcore_b.setup_extras_pre()\n",
    "models_b = warpcore_b.setup_models(extras_b)\n",
    "# models_b.generator.bfloat16().eval().requires_grad_(False)\n",
    "print(\"STAGE B READY\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bf07d742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ModuleList()\n"
     ]
    }
   ],
   "source": [
    "lora_modules = nn.ModuleList()\n",
    "for module in model.modules():\n",
    "    if isinstance(module, LoRA) or (hasattr(module, '_fsdp_wrapped_module') and isinstance(module._fsdp_wrapped_module, LoRA)):\n",
    "        lora_modules.append(module)      \n",
    "print(len(lora_modules), lora_modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4e0708",
   "metadata": {},
   "source": [
    "# CLIP STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59005dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReToken(nn.Module):\n",
    "    def __init__(self, indices=None):\n",
    "        super().__init__()\n",
    "        assert indices is not None\n",
    "        self.embeddings = nn.Parameter(torch.zeros(len(indices), 1280))\n",
    "        self.register_buffer('indices', torch.tensor(indices))\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        for i, idx in enumerate(self.indices):\n",
    "            embeddings[idx] += self.embeddings[i]\n",
    "        return embeddings\n",
    "    \n",
    "def apply_retoken(module, indices=None):\n",
    "    def check_parameter(module, name):\n",
    "        return hasattr(module, name) and not torch.nn.utils.parametrize.is_parametrized(module, name) and isinstance(getattr(module, name), nn.Parameter)\n",
    "\n",
    "    if check_parameter(module, \"weight\"):\n",
    "        torch.nn.utils.parametrize.register_parametrization(module, 'weight', ReToken(indices=indices))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c44b53ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91edc042ddea4691a386cc9b3ebe5091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49408\n",
      "49409\n"
     ]
    }
   ],
   "source": [
    "clip_tokenizer = AutoTokenizer.from_pretrained('laion/CLIP-ViT-bigG-14-laion2B-39B-b160k')\n",
    "clip_model = CLIPModel.from_pretrained('laion/CLIP-ViT-bigG-14-laion2B-39B-b160k')\n",
    "clip_text_model = clip_model.text_model.to('cpu').eval().requires_grad_(False)\n",
    "\n",
    "print(len(clip_tokenizer.vocab))\n",
    "clip_tokenizer.add_tokens([\"[snail]\"])\n",
    "print(len(clip_tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "42ba912f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[49406,   518, 23132,   533,  2442, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407]])\n",
      "tensor([[49406,   518, 34928,   631,  2442, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407]])\n",
      "tensor([[49406,   518, 49408,   533,  2442, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407]])\n"
     ]
    }
   ],
   "source": [
    "tokens = clip_tokenizer(['the snail is small'], truncation=True, padding=\"max_length\", max_length=clip_tokenizer.model_max_length, return_tensors=\"pt\")\n",
    "print(tokens['input_ids'])\n",
    "\n",
    "tokens = clip_tokenizer(['the snails are small'], truncation=True, padding=\"max_length\", max_length=clip_tokenizer.model_max_length, return_tensors=\"pt\")\n",
    "print(tokens['input_ids'])\n",
    "\n",
    "tokens = clip_tokenizer(['the [snail] is small'], truncation=True, padding=\"max_length\", max_length=clip_tokenizer.model_max_length, return_tensors=\"pt\")\n",
    "print(tokens['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "aa54d99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34928, 23132, 49408]\n",
      ">> 0 tensor(34928)\n",
      ">> 1 tensor(23132)\n",
      ">> 2 tensor(49408)\n"
     ]
    }
   ],
   "source": [
    "update_indices = [v for k, v in clip_tokenizer.vocab.items() if re.search(\"^snail\", k) is not None]\n",
    "update_indices += [len(clip_tokenizer.vocab)-1]\n",
    "print(update_indices)\n",
    "\n",
    "clip_text_model.embeddings.token_embedding.weight.data = torch.cat([\n",
    "    clip_text_model.embeddings.token_embedding.weight.data, \n",
    "    torch.zeros_like(clip_text_model.embeddings.token_embedding.weight.data)[:1]\n",
    "], dim=0)\n",
    "\n",
    "apply_retoken(clip_text_model.embeddings.token_embedding, update_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "977bb26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 0 tensor(34928)\n",
      ">> 1 tensor(23132)\n",
      ">> 2 tensor(49408)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0071,  0.0082, -0.0185,  ..., -0.0069, -0.0014,  0.0088],\n",
       "        [ 0.0186, -0.0301,  0.0130,  ...,  0.0110, -0.0009, -0.0193],\n",
       "        [-0.0017,  0.0051,  0.0044,  ...,  0.0016,  0.0092, -0.0060],\n",
       "        ...,\n",
       "        [ 0.0066, -0.0018,  0.0110,  ...,  0.0049, -0.0225,  0.0067],\n",
       "        [-0.0001,  0.0223, -0.0089,  ...,  0.0011, -0.0195, -0.0008],\n",
       "        [ 0.0013,  0.0120, -0.0106,  ..., -0.0001, -0.0024,  0.0111]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_text_model.embeddings.token_embedding(torch.randint(0, len(clip_tokenizer.vocab), size=(100,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "14d6448d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReToken()"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_text_model.embeddings.token_embedding.parametrizations.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "57b0b1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ModuleList(\n",
      "  (0): ReToken()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainable_modules = nn.ModuleDict()\n",
    "trainable_modules['retokens'] = nn.ModuleList()\n",
    "\n",
    "for module in clip_text_model.embeddings.token_embedding.modules():\n",
    "    if isinstance(module, ReToken) or (hasattr(module, '_fsdp_wrapped_module') and isinstance(module._fsdp_wrapped_module, ReToken)):\n",
    "        trainable_modules['retokens'].append(module)\n",
    "print(len(trainable_modules['retokens']), trainable_modules['retokens'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "dd289947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReToken()"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_text_model.embeddings.token_embedding.parametrizations.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "6157ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributed.fsdp import FullyShardedDataParallel as FSDP, ShardingStrategy\n",
    "from torch.distributed.fsdp.wrap import ModuleWrapPolicy\n",
    "from torch.distributed.fsdp.wrap import size_based_auto_wrap_policy\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "import functools\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(64, 64),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.Linear(64, 64),\n",
    ")\n",
    "\n",
    "submodules = nn.ModuleList([model[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2b5dfc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullyShardedDataParallel(\n",
      "  (_fsdp_wrapped_module): ModuleList(\n",
      "    (0): FullyShardedDataParallel(\n",
      "      (_fsdp_wrapped_module): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dist_file_path = f\"{os.getcwd()}/dist_file_test\"\n",
    "init_process_group(\n",
    "    backend=\"nccl\",\n",
    "    rank=0,\n",
    "    world_size=1,\n",
    "    init_method=f\"file://{dist_file_path}\",\n",
    ")\n",
    "\n",
    "# fsdp_auto_wrap_policy = ModuleWrapPolicy([nn.Linear])    \n",
    "fsdp_auto_wrap_policy = functools.partial(size_based_auto_wrap_policy, min_num_params=3000)\n",
    "submodules = FSDP(submodules, auto_wrap_policy=fsdp_auto_wrap_policy, device_id=0)\n",
    "print(submodules)\n",
    "print(model)\n",
    "\n",
    "destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "30c2d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "12a9b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.functional.one_hot(torch.tensor(5), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3cf35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
